{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About Grafana-Zabbix plugin Grafana-Zabbix is a plugin for Grafana allowing to visualize monitoring data from Zabbix and create dashboards for analyzing metrics and realtime monitoring. Main goals of this project are extend Zabbix capabilities for monitoring data visualization and provide quick and powerful way to create dashboards. It is possible due both Grafana and Grafana-Zabbix plugin features. Community Resources, Feedback, and Support This project is being started as a simple plugin for Grafana. But many powerful features and improvements come from community. So don't hesitate to give any feedback and together we will make this tool better. If you have any troubles with Grafana or you just want clarification on a feature, there are a number of ways to get help: Troubleshooting guide Search closed and open issues on GitHub Grafana Community Twitter Or you can send me email . Support Project I develop this project in my free time, but if you really find it helpful and promising, you can support me. There are some ways to do this. You can donate any reasonable amount, or you can request a feature development, interesting for you (for example, Triggers panel was sponsored by Core IT Project ). License By utilizing this software, you agree to the terms of the included license. Grafana-Zabbix plugin is licensed under the Apache 2.0 agreement. See LICENSE for the full license terms.","title":"About Grafana-Zabbix"},{"location":"#about-grafana-zabbix-plugin","text":"Grafana-Zabbix is a plugin for Grafana allowing to visualize monitoring data from Zabbix and create dashboards for analyzing metrics and realtime monitoring. Main goals of this project are extend Zabbix capabilities for monitoring data visualization and provide quick and powerful way to create dashboards. It is possible due both Grafana and Grafana-Zabbix plugin features.","title":"About Grafana-Zabbix plugin"},{"location":"#community-resources-feedback-and-support","text":"This project is being started as a simple plugin for Grafana. But many powerful features and improvements come from community. So don't hesitate to give any feedback and together we will make this tool better. If you have any troubles with Grafana or you just want clarification on a feature, there are a number of ways to get help: Troubleshooting guide Search closed and open issues on GitHub Grafana Community Twitter Or you can send me email .","title":"Community Resources, Feedback, and Support"},{"location":"#support-project","text":"I develop this project in my free time, but if you really find it helpful and promising, you can support me. There are some ways to do this. You can donate any reasonable amount, or you can request a feature development, interesting for you (for example, Triggers panel was sponsored by Core IT Project ).","title":"Support Project"},{"location":"#license","text":"By utilizing this software, you agree to the terms of the included license. Grafana-Zabbix plugin is licensed under the Apache 2.0 agreement. See LICENSE for the full license terms.","title":"License"},{"location":"features/","text":"Feature Highlights Grafana in couple with Grafana-Zabbix plugin allows to create great dashboards. There is some features: Rich graphing features Create interactive and reusable dashboards with template variables Show events on graphs with Annotations Select multiple metrics by using Regex Display active problems with Triggers panel Transform and shape your data with metric processing functions (Avg, Median, Min, Max, Multiply, Summarize, Time shift, Alias) Find problems faster with Alerting feature Mix metrics from multiple data sources in the same dashboard or even graph Discover and share dashboards in the official library","title":"Feature Highlights"},{"location":"features/#feature-highlights","text":"Grafana in couple with Grafana-Zabbix plugin allows to create great dashboards. There is some features: Rich graphing features Create interactive and reusable dashboards with template variables Show events on graphs with Annotations Select multiple metrics by using Regex Display active problems with Triggers panel Transform and shape your data with metric processing functions (Avg, Median, Min, Max, Multiply, Summarize, Time shift, Alias) Find problems faster with Alerting feature Mix metrics from multiple data sources in the same dashboard or even graph Discover and share dashboards in the official library","title":"Feature Highlights"},{"location":"configuration/","text":"Configuration Enable plugin Go to the plugins in Grafana side panel, select Apps tab, then select Zabbix , open Config tab and enable plugin. Configure Zabbix data source After enabling plugin you can add Zabbix data source. To add new Zabbix data source open Data Sources in side panel, click Add data source and select Zabbix from dropdown list. HTTP settings Url : set Zabbix API url (full path with api_jsonrpc.php ). Access : Proxy : access via Grafana backend Direct : access from browser. Http Auth : configure if you use proxy authentication. Basic Auth : With Credentials : Proxy access means that the Grafana backend will proxy all requests from the browser, and send them on to the Data Source. This is useful because it can eliminate CORS (Cross Origin Site Resource) issues, as well as eliminate the need to disseminate authentication details to the Data Source to the browser. Direct access is still supported because in some cases it may be useful to access a Data Source directly depending on the use case and topology of Grafana, the user, and the Data Source. Zabbix API details User and Password : setup login for access to Zabbix API. Also check user's permissions in Zabbix if you can't get any groups and hosts in Grafana. Trends : enable if you use Zabbix 3.x or patch for trends support in Zabbix 2.x ( ZBXNEXT-1193 ). This option strictly recommended for displaying long time periods (more than few days, depending of your item's updating interval in Zabbix) because few days of item history contains tons of points. Using trends will increase Grafana performance. After : time after which trends will be used. Best practice is to set this value to your history storage period (7d, 30d, etc). Default is 7d (7 days). You can set the time in Grafana format. Valid time specificators are: h - hours d - days M - months Range : Time range width after which trends will be used instead of history. It's better to set this value in range of 4 to 7 days to prevent loading large amount of history data. Default is 4 days. Cache TTL : plugin caches some api requests for increasing performance. Set this value to desired cache lifetime (this option affect data like items list). Direct DB Connection Direct DB Connection allows plugin to use existing SQL data source for querying history data directly from Zabbix database. This way usually faster than pulling data from Zabbix API, especially on the wide time ranges, and reduces amount of data transferred. Read how to configure SQL data source in Grafana. Enable : enable Direct DB Connection. Data Source : Select Data Source for Zabbix history database. Retention Policy (InfluxDB only): Specify retention policy name for fetching long-term stored data. Grafana will fetch data from this retention policy if query time range suitable for trends query. Leave it blank if only default retention policy used. Supported databases MySQL , PostgreSQL , InfluxDB are supported as sources of historical data for the plugin. Alerting Enable alerting : enable limited alerting support. Add thresholds : get thresholds info from zabbix triggers and add it to graphs. For example, if you have trigger {Zabbix server:system.cpu.util[,iowait].avg(5m)} 20 , threshold will be set to 20. Min severity : minimum trigger severity for showing alert info (OK/Problem). Then click Add - datasource will be added and you can check connection using Test Connection button. This feature can help to find some mistakes like invalid user name or password, wrong api url. Import example dashboards You can import dashboard examples from Dashboards tab in plugin config. Note about Zabbix 2.2 or less Zabbix API (api_jsonrpc.php) before zabbix 2.4 don't allow cross-domain requests (CORS). And you can get HTTP error 412 (Precondition Failed). To fix it add this code to api_jsonrpc.php immediately after the copyright: header('Access-Control-Allow-Origin: *'); header('Access-Control-Allow-Headers: Content-Type'); header('Access-Control-Allow-Methods: POST'); header('Access-Control-Max-Age: 1000'); if ($_SERVER['REQUEST_METHOD'] === 'OPTIONS') { return; } before require_once dirname(__FILE__).'/include/func.inc.php'; require_once dirname(__FILE__).'/include/classes/core/CHttpRequest.php'; Full fix listing . For more details see zabbix issues ZBXNEXT-1377 and ZBX-8459 . Note about Browser Cache After updating plugin, clear browser cache and reload application page. See details for Chrome , Firefox . You need to clear cache only, not cookies, history and other data.","title":"Configuration"},{"location":"configuration/#configuration","text":"","title":"Configuration"},{"location":"configuration/#enable-plugin","text":"Go to the plugins in Grafana side panel, select Apps tab, then select Zabbix , open Config tab and enable plugin.","title":"Enable plugin"},{"location":"configuration/#configure-zabbix-data-source","text":"After enabling plugin you can add Zabbix data source. To add new Zabbix data source open Data Sources in side panel, click Add data source and select Zabbix from dropdown list.","title":"Configure Zabbix data source"},{"location":"configuration/#http-settings","text":"Url : set Zabbix API url (full path with api_jsonrpc.php ). Access : Proxy : access via Grafana backend Direct : access from browser. Http Auth : configure if you use proxy authentication. Basic Auth : With Credentials : Proxy access means that the Grafana backend will proxy all requests from the browser, and send them on to the Data Source. This is useful because it can eliminate CORS (Cross Origin Site Resource) issues, as well as eliminate the need to disseminate authentication details to the Data Source to the browser. Direct access is still supported because in some cases it may be useful to access a Data Source directly depending on the use case and topology of Grafana, the user, and the Data Source.","title":"HTTP settings"},{"location":"configuration/#zabbix-api-details","text":"User and Password : setup login for access to Zabbix API. Also check user's permissions in Zabbix if you can't get any groups and hosts in Grafana. Trends : enable if you use Zabbix 3.x or patch for trends support in Zabbix 2.x ( ZBXNEXT-1193 ). This option strictly recommended for displaying long time periods (more than few days, depending of your item's updating interval in Zabbix) because few days of item history contains tons of points. Using trends will increase Grafana performance. After : time after which trends will be used. Best practice is to set this value to your history storage period (7d, 30d, etc). Default is 7d (7 days). You can set the time in Grafana format. Valid time specificators are: h - hours d - days M - months Range : Time range width after which trends will be used instead of history. It's better to set this value in range of 4 to 7 days to prevent loading large amount of history data. Default is 4 days. Cache TTL : plugin caches some api requests for increasing performance. Set this value to desired cache lifetime (this option affect data like items list).","title":"Zabbix API details"},{"location":"configuration/#direct-db-connection","text":"Direct DB Connection allows plugin to use existing SQL data source for querying history data directly from Zabbix database. This way usually faster than pulling data from Zabbix API, especially on the wide time ranges, and reduces amount of data transferred. Read how to configure SQL data source in Grafana. Enable : enable Direct DB Connection. Data Source : Select Data Source for Zabbix history database. Retention Policy (InfluxDB only): Specify retention policy name for fetching long-term stored data. Grafana will fetch data from this retention policy if query time range suitable for trends query. Leave it blank if only default retention policy used.","title":"Direct DB Connection"},{"location":"configuration/#supported-databases","text":"MySQL , PostgreSQL , InfluxDB are supported as sources of historical data for the plugin.","title":"Supported databases"},{"location":"configuration/#alerting","text":"Enable alerting : enable limited alerting support. Add thresholds : get thresholds info from zabbix triggers and add it to graphs. For example, if you have trigger {Zabbix server:system.cpu.util[,iowait].avg(5m)} 20 , threshold will be set to 20. Min severity : minimum trigger severity for showing alert info (OK/Problem). Then click Add - datasource will be added and you can check connection using Test Connection button. This feature can help to find some mistakes like invalid user name or password, wrong api url.","title":"Alerting"},{"location":"configuration/#import-example-dashboards","text":"You can import dashboard examples from Dashboards tab in plugin config.","title":"Import example dashboards"},{"location":"configuration/#note-about-zabbix-22-or-less","text":"Zabbix API (api_jsonrpc.php) before zabbix 2.4 don't allow cross-domain requests (CORS). And you can get HTTP error 412 (Precondition Failed). To fix it add this code to api_jsonrpc.php immediately after the copyright: header('Access-Control-Allow-Origin: *'); header('Access-Control-Allow-Headers: Content-Type'); header('Access-Control-Allow-Methods: POST'); header('Access-Control-Max-Age: 1000'); if ($_SERVER['REQUEST_METHOD'] === 'OPTIONS') { return; } before require_once dirname(__FILE__).'/include/func.inc.php'; require_once dirname(__FILE__).'/include/classes/core/CHttpRequest.php'; Full fix listing . For more details see zabbix issues ZBXNEXT-1377 and ZBX-8459 .","title":"Note about Zabbix 2.2 or less"},{"location":"configuration/#note-about-browser-cache","text":"After updating plugin, clear browser cache and reload application page. See details for Chrome , Firefox . You need to clear cache only, not cookies, history and other data.","title":"Note about Browser Cache"},{"location":"configuration/direct_db_datasource/","text":"SQL Data Source Configuration MySQL In order to use Direct DB Connection feature you should configure SQL data source first. Select MySQL data source type and provide your database host address and port (3306 is default for MySQL). Fill database name (usually, zabbix ) and specify credentials. Security notes As you can see in User Permission note, Grafana doesn't restrict any queries to the database. So you should be careful and create a special user with limited access to Zabbix database. Grafana-Zabbix plugin uses only SELECT queries to history , history_uint , trends and trends_uint tables. So it's reasonable to grant only SELECT privileges to these tables for grafana user. But if you want to use this MySQL data source for querying another data, you can grant SELECT privileges to entire zabbix database. Also, all queries are invoked by grafana-server, so you can restrict connection to only grafana host. GRANT SELECT ON zabbix.* TO 'grafana'@'grafana-host' identified by 'password'; PostgreSQL Select PostgreSQL data source type and provide your database host address and port (5432 is default). Fill database name (usually, zabbix ) and specify credentials. Security notes Make sure you use read-only user for Zabbix database. InfluxDB Select InfluxDB data source type and provide your InfluxDB instance host address and port (8086 is default). Fill database name you configured in the effluence module config (usually, zabbix ) and specify credentials.","title":"Direct DB Connection Configuration"},{"location":"configuration/direct_db_datasource/#sql-data-source-configuration","text":"","title":"SQL Data Source Configuration"},{"location":"configuration/direct_db_datasource/#mysql","text":"In order to use Direct DB Connection feature you should configure SQL data source first. Select MySQL data source type and provide your database host address and port (3306 is default for MySQL). Fill database name (usually, zabbix ) and specify credentials.","title":"MySQL"},{"location":"configuration/direct_db_datasource/#security-notes","text":"As you can see in User Permission note, Grafana doesn't restrict any queries to the database. So you should be careful and create a special user with limited access to Zabbix database. Grafana-Zabbix plugin uses only SELECT queries to history , history_uint , trends and trends_uint tables. So it's reasonable to grant only SELECT privileges to these tables for grafana user. But if you want to use this MySQL data source for querying another data, you can grant SELECT privileges to entire zabbix database. Also, all queries are invoked by grafana-server, so you can restrict connection to only grafana host. GRANT SELECT ON zabbix.* TO 'grafana'@'grafana-host' identified by 'password';","title":"Security notes"},{"location":"configuration/direct_db_datasource/#postgresql","text":"Select PostgreSQL data source type and provide your database host address and port (5432 is default). Fill database name (usually, zabbix ) and specify credentials.","title":"PostgreSQL"},{"location":"configuration/direct_db_datasource/#security-notes_1","text":"Make sure you use read-only user for Zabbix database.","title":"Security notes"},{"location":"configuration/direct_db_datasource/#influxdb","text":"Select InfluxDB data source type and provide your InfluxDB instance host address and port (8086 is default). Fill database name you configured in the effluence module config (usually, zabbix ) and specify credentials.","title":"InfluxDB"},{"location":"configuration/provisioning/","text":"Provisioning Grafana-Zabbix plugin It\u2019s now possible to configure datasources using config files with Grafana\u2019s provisioning system. You can read more about how it works and all the settings you can set for datasources on the provisioning docs page Example Datasource Config File apiVersion: 1 datasources: - name: Zabbix type: alexanderzobnin-zabbix-datasource access: proxy url: http://localhost/zabbix/api_jsonrpc.php isDefault: true jsonData: # Zabbix API credentials username: zabbix password: zabbix # Trends options trends: true trendsFrom: 7d trendsRange: 4d # Cache update interval cacheTTL: 1h # Alerting options alerting: true addThresholds: false alertingMinSeverity: 3 # Disable acknowledges for read-only users disableReadOnlyUsersAck: true # Direct DB Connection options dbConnectionEnable: true # Name of existing datasource for Direct DB Connection dbConnectionDatasourceName: MySQL Zabbix # Retention policy name (InfluxDB only) for fetching long-term stored data. # Leave it blank if only default retention policy used. dbConnectionRetentionPolicy: one_year version: 1 editable: false - name: MySQL Zabbix type: mysql url: localhost:3306 database: zabbix user: grafana password: password","title":"Provisioning"},{"location":"configuration/provisioning/#provisioning-grafana-zabbix-plugin","text":"It\u2019s now possible to configure datasources using config files with Grafana\u2019s provisioning system. You can read more about how it works and all the settings you can set for datasources on the provisioning docs page","title":"Provisioning Grafana-Zabbix plugin"},{"location":"configuration/provisioning/#example-datasource-config-file","text":"apiVersion: 1 datasources: - name: Zabbix type: alexanderzobnin-zabbix-datasource access: proxy url: http://localhost/zabbix/api_jsonrpc.php isDefault: true jsonData: # Zabbix API credentials username: zabbix password: zabbix # Trends options trends: true trendsFrom: 7d trendsRange: 4d # Cache update interval cacheTTL: 1h # Alerting options alerting: true addThresholds: false alertingMinSeverity: 3 # Disable acknowledges for read-only users disableReadOnlyUsersAck: true # Direct DB Connection options dbConnectionEnable: true # Name of existing datasource for Direct DB Connection dbConnectionDatasourceName: MySQL Zabbix # Retention policy name (InfluxDB only) for fetching long-term stored data. # Leave it blank if only default retention policy used. dbConnectionRetentionPolicy: one_year version: 1 editable: false - name: MySQL Zabbix type: mysql url: localhost:3306 database: zabbix user: grafana password: password","title":"Example Datasource Config File"},{"location":"configuration/troubleshooting/","text":"Troubleshooting See Grafana troubleshooting for general connection issues. If you have a problem with Zabbix datasource, you should open a support issue . Before you do that please search the existing closed or open issues.","title":"Troubleshooting"},{"location":"configuration/troubleshooting/#troubleshooting","text":"See Grafana troubleshooting for general connection issues. If you have a problem with Zabbix datasource, you should open a support issue . Before you do that please search the existing closed or open issues.","title":"Troubleshooting"},{"location":"guides/gettingstarted/","text":"Getting Started with Grafana-Zabbix After you installed and configured Grafana-Zabbix data source let's create a simple dashboard. Simple Graph Add new Graph panel to dashboard. Select metrics from dropdown or start to type to filter results Let's create 15 min avg processor load graph. Select Host Group, Host, Application (optional - you can leave it blank) and Item. Multiple Items On One Graph You can build graphs with lots of items using Regular Expressions inside metric field. Grafana uses JavaScript regex implementation. For example, if you need to show CPU time (user, system, iowait, etc) you may create graph using this regex in Item field: /CPU (?!idle).* time/ Another case to use regex is comparing the same metrics for different hosts. Use /.*/ regex for showing all metrics or write your own filter. For example, I want to show CPU system time for all hosts which name started with backend from all host groups. I use /.*/ for Group, /^backend/ for Host and CPU system time for Item. Bar Chart Let's create a graph which show queries stats for MySQL database. Select Group, Host, Application ( MySQL in my case) and Items. I use /MySQL .* operations/ regex for filtering different types of operations. To show graph as Bar Chart, go to the Display tab, uncheck Lines and set Bars . Also, enable Stack checkbox for showing stacked bars. But this graph doesn't look good because it contains too many bars. We can fix it by using Max data points parameter. Go to the Metrics tab and set Max data points to 50 for example. Ok, looks pretty! Singlestat and Gauges Sometimes you may need to show just a big single value for particular metric. Use Grafana's Singlestat panel in this case. Let's create panel which shows CPU user time metric. Suppose that you want to set units as percents and show Gauge for this value. Go to the Options tab and set units to percent (0-100) . Then enable Show option for Gauge and set Min and Max values for your metric (0-100 in our case). Set thresholds if you want to see it on Gauge ( 50,80 for example). Great, looks cool. Read more about Singlestat panel in Grafana docs . And all together:","title":"Getting Started"},{"location":"guides/gettingstarted/#getting-started-with-grafana-zabbix","text":"After you installed and configured Grafana-Zabbix data source let's create a simple dashboard.","title":"Getting Started with Grafana-Zabbix"},{"location":"guides/gettingstarted/#simple-graph","text":"Add new Graph panel to dashboard. Select metrics from dropdown or start to type to filter results Let's create 15 min avg processor load graph. Select Host Group, Host, Application (optional - you can leave it blank) and Item.","title":"Simple Graph"},{"location":"guides/gettingstarted/#multiple-items-on-one-graph","text":"You can build graphs with lots of items using Regular Expressions inside metric field. Grafana uses JavaScript regex implementation. For example, if you need to show CPU time (user, system, iowait, etc) you may create graph using this regex in Item field: /CPU (?!idle).* time/ Another case to use regex is comparing the same metrics for different hosts. Use /.*/ regex for showing all metrics or write your own filter. For example, I want to show CPU system time for all hosts which name started with backend from all host groups. I use /.*/ for Group, /^backend/ for Host and CPU system time for Item.","title":"Multiple Items On One Graph"},{"location":"guides/gettingstarted/#bar-chart","text":"Let's create a graph which show queries stats for MySQL database. Select Group, Host, Application ( MySQL in my case) and Items. I use /MySQL .* operations/ regex for filtering different types of operations. To show graph as Bar Chart, go to the Display tab, uncheck Lines and set Bars . Also, enable Stack checkbox for showing stacked bars. But this graph doesn't look good because it contains too many bars. We can fix it by using Max data points parameter. Go to the Metrics tab and set Max data points to 50 for example. Ok, looks pretty!","title":"Bar Chart"},{"location":"guides/gettingstarted/#singlestat-and-gauges","text":"Sometimes you may need to show just a big single value for particular metric. Use Grafana's Singlestat panel in this case. Let's create panel which shows CPU user time metric. Suppose that you want to set units as percents and show Gauge for this value. Go to the Options tab and set units to percent (0-100) . Then enable Show option for Gauge and set Min and Max values for your metric (0-100 in our case). Set thresholds if you want to see it on Gauge ( 50,80 for example). Great, looks cool. Read more about Singlestat panel in Grafana docs . And all together:","title":"Singlestat and Gauges"},{"location":"guides/templating/","text":"Templating Guide You can use template variables for creating highly reusable and interactive dashboards. General idea of templating is allow Grafana to get different metrics from data source and provide a way to change it on the fly without modifying dashboard. In case of Zabbix it means that you can get list of Host Groups, Hosts, Applications or Items and add it as a variables. Creating Variable To create template variable click the cog icon on the top navigation bar and choose Templating . When you click New button, you'll see template variable editor. It contains these sections: Variable Name Name of the variable. You should use this name in queries. Label Visible label for variable. Use when you want to display different name on dashboard. For instance, Host Group instead host_group . Type By default Query type is selected. It means that Grafana asks data source for values of variable. But there are some other types: Interval (just a time interval), Data source (You can switch data source, for example, if you have more than one Zabbix instance and each added into Grafana as data source), Custom (you can set any predefined values for variable) and Constant . Query Options Data source Data source used for querying variable values. Refresh When to update the values of this variable. Query Query string. Regex Use regex if you need to filter values or extract a part of value. Selection Options Multi-value Enable, if you want to select multiple values at the same time. Value groups/tags (Experimental feature) Query Format Template variable query in Zabbix data source is a string which contains 4 parts wrapped in braces ( {} ). You still can use a period ( . ), but it's deprecated and will be removed in future. {host group}{host}{application}{item name} For example, {Zabbix servers}{Zabbix server}{CPU}{*} {Frontend}{web01.mydomain.com}{*}{*} Each part can be a name of corresponding metric or * , which means all metrics . Examples: {*} returns list of all available Host Groups {*}{*} all hosts in Zabbix {Network}{*} returns all hosts in group Network {Linux servers}{*}{*} returns all applications from hosts in Linux servers group {Linux servers}{backend01}{CPU}{*} returns all items from backend01 belonging to CPU application. You can use another variable as a part of query. For instance, you have variable group , which returns list of host groups and want to use it for querying hosts in selected group only. Here's a query for this case: {$group}{*} Variables Usage When you create a variable, you can use it as a part of data source query. Grafana also supports variables in different places like panel's and row's titles, Text panel's content, etc. Note, that you should add $ sign before variable's name ( $host for host variable). See more about templating in Grafana docs","title":"Templating"},{"location":"guides/templating/#templating-guide","text":"You can use template variables for creating highly reusable and interactive dashboards. General idea of templating is allow Grafana to get different metrics from data source and provide a way to change it on the fly without modifying dashboard. In case of Zabbix it means that you can get list of Host Groups, Hosts, Applications or Items and add it as a variables.","title":"Templating Guide"},{"location":"guides/templating/#creating-variable","text":"To create template variable click the cog icon on the top navigation bar and choose Templating . When you click New button, you'll see template variable editor. It contains these sections:","title":"Creating Variable"},{"location":"guides/templating/#variable","text":"Name Name of the variable. You should use this name in queries. Label Visible label for variable. Use when you want to display different name on dashboard. For instance, Host Group instead host_group . Type By default Query type is selected. It means that Grafana asks data source for values of variable. But there are some other types: Interval (just a time interval), Data source (You can switch data source, for example, if you have more than one Zabbix instance and each added into Grafana as data source), Custom (you can set any predefined values for variable) and Constant .","title":"Variable"},{"location":"guides/templating/#query-options","text":"Data source Data source used for querying variable values. Refresh When to update the values of this variable. Query Query string. Regex Use regex if you need to filter values or extract a part of value.","title":"Query Options"},{"location":"guides/templating/#selection-options","text":"Multi-value Enable, if you want to select multiple values at the same time.","title":"Selection Options"},{"location":"guides/templating/#value-groupstags-experimental-feature","text":"","title":"Value groups/tags (Experimental feature)"},{"location":"guides/templating/#query-format","text":"Template variable query in Zabbix data source is a string which contains 4 parts wrapped in braces ( {} ). You still can use a period ( . ), but it's deprecated and will be removed in future. {host group}{host}{application}{item name} For example, {Zabbix servers}{Zabbix server}{CPU}{*} {Frontend}{web01.mydomain.com}{*}{*} Each part can be a name of corresponding metric or * , which means all metrics . Examples: {*} returns list of all available Host Groups {*}{*} all hosts in Zabbix {Network}{*} returns all hosts in group Network {Linux servers}{*}{*} returns all applications from hosts in Linux servers group {Linux servers}{backend01}{CPU}{*} returns all items from backend01 belonging to CPU application. You can use another variable as a part of query. For instance, you have variable group , which returns list of host groups and want to use it for querying hosts in selected group only. Here's a query for this case: {$group}{*}","title":"Query Format"},{"location":"guides/templating/#variables-usage","text":"When you create a variable, you can use it as a part of data source query. Grafana also supports variables in different places like panel's and row's titles, Text panel's content, etc. Note, that you should add $ sign before variable's name ( $host for host variable). See more about templating in Grafana docs","title":"Variables Usage"},{"location":"installation/","text":"Installation Using grafana-cli tool Get list of available plugins grafana-cli plugins list-remote Install zabbix plugin grafana-cli plugins install alexanderzobnin-zabbix-app Restart grafana after installing plugins systemctl restart grafana-server Read more about installing plugins in Grafana docs WARNING! The only reliable installation method is grafana-cli . Any other way should be treated as a workaround and doesn't provide any backward-compatibility guaranties. From github repo WARNING! This way doesn't work anymore ( dist/ folder was removed from git). Use grafana-cli or build plugin from sources. Building from sources If you want to build a package yourself, or contribute - read building instructions .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#using-grafana-cli-tool","text":"Get list of available plugins grafana-cli plugins list-remote Install zabbix plugin grafana-cli plugins install alexanderzobnin-zabbix-app Restart grafana after installing plugins systemctl restart grafana-server Read more about installing plugins in Grafana docs WARNING! The only reliable installation method is grafana-cli . Any other way should be treated as a workaround and doesn't provide any backward-compatibility guaranties.","title":"Using grafana-cli tool"},{"location":"installation/#from-github-repo","text":"WARNING! This way doesn't work anymore ( dist/ folder was removed from git). Use grafana-cli or build plugin from sources.","title":"From github repo"},{"location":"installation/#building-from-sources","text":"If you want to build a package yourself, or contribute - read building instructions .","title":"Building from sources"},{"location":"installation/run_from_master/","text":"Run from master If you want to build a package yourself, or contribute - here is a guide for how to do that. Dependencies NodeJS LTS Building plugin npm install -g yarn yarn install --pure-lockfile yarn build To build plugin and rebuild on file change yarn watch Run tests yarn test Run tests on file change yarn jest","title":"Building from sources"},{"location":"installation/run_from_master/#run-from-master","text":"If you want to build a package yourself, or contribute - here is a guide for how to do that.","title":"Run from master"},{"location":"installation/run_from_master/#dependencies","text":"NodeJS LTS","title":"Dependencies"},{"location":"installation/run_from_master/#building-plugin","text":"npm install -g yarn yarn install --pure-lockfile yarn build","title":"Building plugin"},{"location":"installation/run_from_master/#to-build-plugin-and-rebuild-on-file-change","text":"yarn watch","title":"To build plugin and rebuild on file change"},{"location":"installation/run_from_master/#run-tests","text":"yarn test","title":"Run tests"},{"location":"installation/run_from_master/#run-tests-on-file-change","text":"yarn jest","title":"Run tests on file change"},{"location":"installation/upgrade/","text":"Upgrade Upgrade from 2.x After enabling Zabbix App go to Data Sources , open your configured Zabbix data source end select Zabbix from Type list again. This is needed because plugin id was changed in Grafana 3.0.","title":"Upgrade"},{"location":"installation/upgrade/#upgrade","text":"","title":"Upgrade"},{"location":"installation/upgrade/#upgrade-from-2x","text":"After enabling Zabbix App go to Data Sources , open your configured Zabbix data source end select Zabbix from Type list again. This is needed because plugin id was changed in Grafana 3.0.","title":"Upgrade from 2.x"},{"location":"reference/alerting/","text":"Alerting Since version 4.0 Grafana has its own alerting engine. Alerting in Grafana allows you to attach rules to your dashboard panels. When you save the dashboard Grafana will extract the alert rules into a separate alert rule storage and schedule them for evaluation. In the alert tab of the graph panel you can configure how often the alert rule should be evaluated and the conditions that need to be met for the alert to change state and trigger its notifications. Read more about alerting feature in Grafana docs . On the other hand, Zabbix has its own alerting system with triggers, events and notifications. And the best way is to combine benefits of these systems into Zabbix plugin for Grafana. So how it works you'll ask? Grafana alerting feature consists of two main parts: Alerting execution engine The alert rules are evaluated in the Grafana backend in a scheduler and query execution engine that is part of core Grafana. Only some data sources are supported right now. They include Graphite, Prometheus, InfluxDB and OpenTSDB. Alerting visualisations Alerts highlight panels with problems and it can easily be found on the dashboard. So Zabbix plugin doesn't use execution engine and doesn't allow to configure rules in Grafana. But it fetches information about triggers related to metrics at particular panel and fires alert state for these panels. So there are three possible cases for each panel: Panel contains Zabbix items which are used in triggers: At least one of these related triggers is in the PROBLEM state. In this case panel will be highlighted with the red glow and broken heart icon. All triggers are in the OK state. Panel will be displayed with green heart icon without highlighting. There aren't triggers related to items on panel. Panel will be displayed without any changes. Note, that only triggers with severity above than configured at Data Source config page will be used for panel state calculation. Also plugin can extract thresholds from trigger expression and set it on graph. You can enable this feature in Data Source config. Thresholds are parts of panel JSON data, so it will be stored in backend if you save dashboard, but plugin marks this thresholds with special tag, so it will be changed or deleted if you change it in Zabbix.","title":"Alerting"},{"location":"reference/alerting/#alerting","text":"Since version 4.0 Grafana has its own alerting engine. Alerting in Grafana allows you to attach rules to your dashboard panels. When you save the dashboard Grafana will extract the alert rules into a separate alert rule storage and schedule them for evaluation. In the alert tab of the graph panel you can configure how often the alert rule should be evaluated and the conditions that need to be met for the alert to change state and trigger its notifications. Read more about alerting feature in Grafana docs . On the other hand, Zabbix has its own alerting system with triggers, events and notifications. And the best way is to combine benefits of these systems into Zabbix plugin for Grafana. So how it works you'll ask? Grafana alerting feature consists of two main parts: Alerting execution engine The alert rules are evaluated in the Grafana backend in a scheduler and query execution engine that is part of core Grafana. Only some data sources are supported right now. They include Graphite, Prometheus, InfluxDB and OpenTSDB. Alerting visualisations Alerts highlight panels with problems and it can easily be found on the dashboard. So Zabbix plugin doesn't use execution engine and doesn't allow to configure rules in Grafana. But it fetches information about triggers related to metrics at particular panel and fires alert state for these panels. So there are three possible cases for each panel: Panel contains Zabbix items which are used in triggers: At least one of these related triggers is in the PROBLEM state. In this case panel will be highlighted with the red glow and broken heart icon. All triggers are in the OK state. Panel will be displayed with green heart icon without highlighting. There aren't triggers related to items on panel. Panel will be displayed without any changes. Note, that only triggers with severity above than configured at Data Source config page will be used for panel state calculation. Also plugin can extract thresholds from trigger expression and set it on graph. You can enable this feature in Data Source config. Thresholds are parts of panel JSON data, so it will be stored in backend if you save dashboard, but plugin marks this thresholds with special tag, so it will be changed or deleted if you change it in Zabbix.","title":"Alerting"},{"location":"reference/datasource-zabbix/","text":"","title":"Zabbix Datasource"},{"location":"reference/direct-db-connection/","text":"Direct DB Connection Since version 4.3 Grafana can use MySQL as a native data source. The idea of Direct DB Connection is that Grafana-Zabbix plugin can use this data source for querying data directly from a Zabbix database. One of the most resource intensive queries for Zabbix API is the history query. For long time intervals history.get returns a huge amount of data. In order to display it, the plugin should adjust time series resolution by using consolidateBy . Ultimately, Grafana displays this reduced time series, but that data should be loaded and processed on the client side first. Direct DB Connection solves these two problems by moving consolidation to the server side. Thus, the client gets a 'ready-to-use' dataset which is much smaller. This allows the data to load faster and the client doesn't spend time processing the data. Also, many users see better performance from direct database queries versus API calls. This could be the result of several reasons, such as the additional PHP layer and additional SQL queries (user permissions checks). Direct DB Connection feature allows using database transparently for querying historical data. Now Grafana-Zabbix plugin supports few databases for history queries: MySQL, PostgreSQL and InfluxDB. Regardless of the database type, idea and data flow remain the same. Data Flow This chart illustrates how the plugin uses both Zabbix API and the MySQL data source for querying different types of data from Zabbix. MySQL data source is used only for pulling history and trend data instead of history.get and trend.get API calls. Query structure Below is an example query for getting history in the Grafana-Zabbix Plugin: MySQL : SELECT itemid AS metric, clock AS time_sec, {aggFunc}(value) as value FROM {historyTable} WHERE itemid IN ({itemids}) AND clock {timeFrom} AND clock {timeTill} GROUP BY time_sec DIV {intervalSec}, metric ORDER BY time_sec ASC PostgreSQL : SELECT to_char(itemid, 'FM99999999999999999999') AS metric, clock / {intervalSec} * {intervalSec} AS time, {aggFunc}(value) AS value FROM {historyTable} WHERE itemid IN ({itemids}) AND clock {timeFrom} AND clock {timeTill} GROUP BY 1, 2 ORDER BY time ASC where {aggFunc} is one of [AVG, MIN, MAX, SUM, COUNT] aggregation functions, {historyTable} is a history table, {intervalSec} - consolidation interval in seconds. When getting trends, the plugin additionally queries a particular value column ( value_avg , value_min or value_max ) which depends on consolidateBy function value: MySQL : SELECT itemid AS metric, clock AS time_sec, {aggFunc}({valueColumn}) as value FROM {trendsTable} WHERE itemid IN ({itemids}) AND clock {timeFrom} AND clock {timeTill} GROUP BY time_sec DIV {intervalSec}, metric ORDER BY time_sec ASC PostgreSQL : SELECT to_char(itemid, 'FM99999999999999999999') AS metric, clock / {intervalSec} * {intervalSec} AS time, {aggFunc}({valueColumn}) AS value FROM {trendsTable} WHERE itemid IN ({itemids}) AND clock {timeFrom} AND clock {timeTill} GROUP BY 1, 2 ORDER BY time ASC Note : these queries may be changed in future, so look into sources for actual query structure. As you can see, the Grafana-Zabbix plugin uses aggregation by a given time interval. This interval is provided by Grafana and depends on the panel width in pixels. Thus, Grafana displays the data in the proper resolution. InfluxDB Zabbix supports loadable modules which makes possible to write history data into an external database. There's a module for InfluxDB written by Gleb Ivanovsky which can export history into InfluxDB in real-time. InfluxDB retention policy In order to keep database size under control, you should use InfluxDB retention policy mechanism. It's possible to create retention policy for long-term data and write aggregated data in the same manner as Zabbix does (trends). Then this retention policy can be used in plugin for getting data after a certain period ( Retention Policy option in data source config). Read more about how to configure retention policy for using with plugin in effluence module docs . InfluxDB Query Eventually, plugin generates InfluxDB query similar to this: SELECT MEAN( value ) FROM history WHERE ( itemid = '10073' OR itemid = '10074') AND time = 1540000000000s AND time = 1540000000060s GROUP BY time(10s), itemid fill(none) Functions usage with Direct DB Connection There's only one function that directly affects the backend data. This function is consolidateBy . Other functions work on the client side and transform data that comes from the backend. So you should clearly understand that this is pre-aggregated data (by AVG, MAX, MIN, etc). For example, say you want to group values by 1 hour interval and max function. If you just apply groupBy(10m, max) function, your result will be wrong, because you would transform data aggregated by default AVG function. You should use consolidateBy(max) coupled with groupBy(10m, max) in order to get a precise result.","title":"Direct DB Connection"},{"location":"reference/direct-db-connection/#direct-db-connection","text":"Since version 4.3 Grafana can use MySQL as a native data source. The idea of Direct DB Connection is that Grafana-Zabbix plugin can use this data source for querying data directly from a Zabbix database. One of the most resource intensive queries for Zabbix API is the history query. For long time intervals history.get returns a huge amount of data. In order to display it, the plugin should adjust time series resolution by using consolidateBy . Ultimately, Grafana displays this reduced time series, but that data should be loaded and processed on the client side first. Direct DB Connection solves these two problems by moving consolidation to the server side. Thus, the client gets a 'ready-to-use' dataset which is much smaller. This allows the data to load faster and the client doesn't spend time processing the data. Also, many users see better performance from direct database queries versus API calls. This could be the result of several reasons, such as the additional PHP layer and additional SQL queries (user permissions checks). Direct DB Connection feature allows using database transparently for querying historical data. Now Grafana-Zabbix plugin supports few databases for history queries: MySQL, PostgreSQL and InfluxDB. Regardless of the database type, idea and data flow remain the same.","title":"Direct DB Connection"},{"location":"reference/direct-db-connection/#data-flow","text":"This chart illustrates how the plugin uses both Zabbix API and the MySQL data source for querying different types of data from Zabbix. MySQL data source is used only for pulling history and trend data instead of history.get and trend.get API calls.","title":"Data Flow"},{"location":"reference/direct-db-connection/#query-structure","text":"Below is an example query for getting history in the Grafana-Zabbix Plugin: MySQL : SELECT itemid AS metric, clock AS time_sec, {aggFunc}(value) as value FROM {historyTable} WHERE itemid IN ({itemids}) AND clock {timeFrom} AND clock {timeTill} GROUP BY time_sec DIV {intervalSec}, metric ORDER BY time_sec ASC PostgreSQL : SELECT to_char(itemid, 'FM99999999999999999999') AS metric, clock / {intervalSec} * {intervalSec} AS time, {aggFunc}(value) AS value FROM {historyTable} WHERE itemid IN ({itemids}) AND clock {timeFrom} AND clock {timeTill} GROUP BY 1, 2 ORDER BY time ASC where {aggFunc} is one of [AVG, MIN, MAX, SUM, COUNT] aggregation functions, {historyTable} is a history table, {intervalSec} - consolidation interval in seconds. When getting trends, the plugin additionally queries a particular value column ( value_avg , value_min or value_max ) which depends on consolidateBy function value: MySQL : SELECT itemid AS metric, clock AS time_sec, {aggFunc}({valueColumn}) as value FROM {trendsTable} WHERE itemid IN ({itemids}) AND clock {timeFrom} AND clock {timeTill} GROUP BY time_sec DIV {intervalSec}, metric ORDER BY time_sec ASC PostgreSQL : SELECT to_char(itemid, 'FM99999999999999999999') AS metric, clock / {intervalSec} * {intervalSec} AS time, {aggFunc}({valueColumn}) AS value FROM {trendsTable} WHERE itemid IN ({itemids}) AND clock {timeFrom} AND clock {timeTill} GROUP BY 1, 2 ORDER BY time ASC Note : these queries may be changed in future, so look into sources for actual query structure. As you can see, the Grafana-Zabbix plugin uses aggregation by a given time interval. This interval is provided by Grafana and depends on the panel width in pixels. Thus, Grafana displays the data in the proper resolution.","title":"Query structure"},{"location":"reference/direct-db-connection/#influxdb","text":"Zabbix supports loadable modules which makes possible to write history data into an external database. There's a module for InfluxDB written by Gleb Ivanovsky which can export history into InfluxDB in real-time.","title":"InfluxDB"},{"location":"reference/direct-db-connection/#influxdb-retention-policy","text":"In order to keep database size under control, you should use InfluxDB retention policy mechanism. It's possible to create retention policy for long-term data and write aggregated data in the same manner as Zabbix does (trends). Then this retention policy can be used in plugin for getting data after a certain period ( Retention Policy option in data source config). Read more about how to configure retention policy for using with plugin in effluence module docs .","title":"InfluxDB retention policy"},{"location":"reference/direct-db-connection/#influxdb-query","text":"Eventually, plugin generates InfluxDB query similar to this: SELECT MEAN( value ) FROM history WHERE ( itemid = '10073' OR itemid = '10074') AND time = 1540000000000s AND time = 1540000000060s GROUP BY time(10s), itemid fill(none)","title":"InfluxDB Query"},{"location":"reference/direct-db-connection/#functions-usage-with-direct-db-connection","text":"There's only one function that directly affects the backend data. This function is consolidateBy . Other functions work on the client side and transform data that comes from the backend. So you should clearly understand that this is pre-aggregated data (by AVG, MAX, MIN, etc). For example, say you want to group values by 1 hour interval and max function. If you just apply groupBy(10m, max) function, your result will be wrong, because you would transform data aggregated by default AVG function. You should use consolidateBy(max) coupled with groupBy(10m, max) in order to get a precise result.","title":"Functions usage with Direct DB Connection"},{"location":"reference/functions/","text":"Functions reference Functions Variables There are some built-in template variables available for using in functions: $__range_ms - panel time range in ms $__range_s - panel time range in seconds $__range - panel time range, string representation ( 30s , 1m , 1h ) $__range_series - invoke function over all series values Examples: groupBy($__range, avg) percentile($__range_series, 95) - 95th percentile over all values Transform groupBy groupBy(interval, function) Takes each timeseries and consolidate its points fallen in the given interval into one point using function , which can be one of: avg , min , max , median . Examples: groupBy(10m, avg) groupBy(1h, median) scale scale(factor) Takes timeseries and multiplies each point by the given factor . Examples: scale(100) scale(0.01) delta delta() Converts absolute values to delta. This function just calculate difference between values. For the per-second calculation use rate() . rate rate() Calculates the per-second rate of increase of the time series. Resistant to counter reset. Suitable for converting of growing counters into the per-sercond rate. movingAverage movingAverage(windowSize) Graphs the moving average of a metric over a fixed number of past points, specified by windowSize param. Examples: movingAverage(60) calculates moving average over 60 points (if metric has 1 second resolution it matches 1 minute window) exponentialMovingAverage exponentialMovingAverage(windowSize) Takes a series of values and a window size and produces an exponential moving average utilizing the following formula: ema(current) = constant * (Current Value) + (1 - constant) * ema(previous) The Constant is calculated as: constant = 2 / (windowSize + 1) If windowSize 1 (0.1, for instance), Constant wouldn't be calculated and will be taken directly from windowSize (Constant = windowSize). It's a bit tricky to graph EMA from the first point of series (not from Nth = windowSize). In order to do it, plugin should fetch previous N points first and calculate simple moving average for it. To avoid it, plugin uses this hack: assume, previous N points have the same average values as first N (windowSize). So you should keep this fact in mind and don't rely on first N points interval. Examples: movingAverage(60) calculates moving average over 60 points (if metric has 1 second resolution it matches 1 minute window) percentile percentile(interval, N) Takes a series of values and a window size and consolidate all its points fallen in the given interval into one point by Nth percentile. Examples: percentile(1h, 99) percentile($__range_series, 95) - 95th percentile over all series values removeAboveValue removeAboveValue(N) Replaces series values with null if value N Examples: removeAboveValue(1) removeBelowValue removeBelowValue(N) Replaces series values with null if value N transformNull transformNull(N) Replaces null values with N Aggregate aggregateBy aggregateBy(interval, function) Takes all timeseries and consolidate all its points fallen in the given interval into one point using function , which can be one of: avg , min , max , median . Examples: aggregateBy(10m, avg) aggregateBy(1h, median) sumSeries sumSeries() This will add metrics together and return the sum at each datapoint. This method required interpolation of each timeseries so it may cause high CPU load. Try to combine it with groupBy() function to reduce load. percentileAgg percentileAgg(interval, N) Takes all timeseries and consolidate all its points fallen in the given interval into one point by Nth percentile. Examples: percentileAgg(1h, 99) percentileAgg($__range_series, 95) - 95th percentile over all values average average(interval) Deprecated , use aggregateBy(interval, avg) instead. min min(interval) Deprecated , use aggregateBy(interval, min) instead. max max(interval) Deprecated , use aggregateBy(interval, max) instead. Filter top top(N, value) Returns top N series, sorted by value , which can be one of: avg , min , max , median . Examples: top(10, avg) top(5, max) bottom bottom(N, value) Returns bottom N series, sorted by value , which can be one of: avg , min , max , median . Examples: bottom(5, avg) Trends trendValue trendValue(valueType) Specifying type of trend value returned by Zabbix when trends are used (avg, min or max). Time timeShift timeShift(interval) Draws the selected metrics shifted in time. If no sign is given, a minus sign ( - ) is implied which will shift the metric back in time. If a plus sign ( + ) is given, the metric will be shifted forward in time. Examples: timeShift(24h) - shift metric back in 24h hours timeShift(-24h) - the same result as for timeShift(24h) timeShift(+1d) - shift metric forward in 1 day Alias Following template variables available for using in setAlias() and replaceAlias() functions: $__zbx_item , $__zbx_item_name - item name $__zbx_item_key - item key $__zbx_host_name - visible name of the host $__zbx_host - technical name of the host Examples: setAlias($__zbx_host_name: $__zbx_item) - backend01: CPU user time setAlias(Item key: $__zbx_item_key) - Item key: system.cpu.load[percpu,avg1] setAlias($__zbx_host_name) - backend01 setAlias setAlias(alias) Returns given alias instead of the metric name. Examples: setAlias(load) setAliasByRegex setAliasByRegex(regex) Returns part of the metric name matched by regex. Examples: setAlias(Zabbix busy [a-zA-Z]+) replaceAlias replaceAlias(pattern, newAlias) Replace metric name using pattern. Pattern is regex or regular string. If regex is used, following special replacement patterns are supported: Pattern Inserts $$ Inserts a \"$\". $ Inserts the matched substring. $` Inserts the portion of the string that precedes the matched substring. $' Inserts the portion of the string that follows the matched substring. $n Where n is a non-negative integer less than 100, inserts the nth parenthesized submatch string, provided the first argument was a RegExp object. For more detais see String.prototype.replace() function. Examples: CPU system time replaceAlias(/CPU (.*) time/, $1) - system backend01: CPU system time replaceAlias(/CPU (.*) time/, $1) - backend01: system backend01: CPU system time replaceAlias(/.*CPU (.*) time/, $1) - system backend01: CPU system time replaceAlias(/(.*): CPU (.*) time/, $1 - $2) - backend01 - system Special consolidateBy consolidateBy(consolidationFunc) When a graph is drawn where width of the graph size in pixels is smaller than the number of datapoints to be graphed, plugin consolidates the values to to prevent line overlap. The consolidateBy() function changes the consolidation function from the default of average to one of sum , min , max or count . Valid function names are sum , avg , min , max and count .","title":"Functions"},{"location":"reference/functions/#functions-reference","text":"","title":"Functions reference"},{"location":"reference/functions/#functions-variables","text":"There are some built-in template variables available for using in functions: $__range_ms - panel time range in ms $__range_s - panel time range in seconds $__range - panel time range, string representation ( 30s , 1m , 1h ) $__range_series - invoke function over all series values Examples: groupBy($__range, avg) percentile($__range_series, 95) - 95th percentile over all values","title":"Functions Variables"},{"location":"reference/functions/#transform","text":"","title":"Transform"},{"location":"reference/functions/#groupby","text":"groupBy(interval, function) Takes each timeseries and consolidate its points fallen in the given interval into one point using function , which can be one of: avg , min , max , median . Examples: groupBy(10m, avg) groupBy(1h, median)","title":"groupBy"},{"location":"reference/functions/#scale","text":"scale(factor) Takes timeseries and multiplies each point by the given factor . Examples: scale(100) scale(0.01)","title":"scale"},{"location":"reference/functions/#delta","text":"delta() Converts absolute values to delta. This function just calculate difference between values. For the per-second calculation use rate() .","title":"delta"},{"location":"reference/functions/#rate","text":"rate() Calculates the per-second rate of increase of the time series. Resistant to counter reset. Suitable for converting of growing counters into the per-sercond rate.","title":"rate"},{"location":"reference/functions/#movingaverage","text":"movingAverage(windowSize) Graphs the moving average of a metric over a fixed number of past points, specified by windowSize param. Examples: movingAverage(60) calculates moving average over 60 points (if metric has 1 second resolution it matches 1 minute window)","title":"movingAverage"},{"location":"reference/functions/#exponentialmovingaverage","text":"exponentialMovingAverage(windowSize) Takes a series of values and a window size and produces an exponential moving average utilizing the following formula: ema(current) = constant * (Current Value) + (1 - constant) * ema(previous) The Constant is calculated as: constant = 2 / (windowSize + 1) If windowSize 1 (0.1, for instance), Constant wouldn't be calculated and will be taken directly from windowSize (Constant = windowSize). It's a bit tricky to graph EMA from the first point of series (not from Nth = windowSize). In order to do it, plugin should fetch previous N points first and calculate simple moving average for it. To avoid it, plugin uses this hack: assume, previous N points have the same average values as first N (windowSize). So you should keep this fact in mind and don't rely on first N points interval. Examples: movingAverage(60) calculates moving average over 60 points (if metric has 1 second resolution it matches 1 minute window)","title":"exponentialMovingAverage"},{"location":"reference/functions/#percentile","text":"percentile(interval, N) Takes a series of values and a window size and consolidate all its points fallen in the given interval into one point by Nth percentile. Examples: percentile(1h, 99) percentile($__range_series, 95) - 95th percentile over all series values","title":"percentile"},{"location":"reference/functions/#removeabovevalue","text":"removeAboveValue(N) Replaces series values with null if value N Examples: removeAboveValue(1)","title":"removeAboveValue"},{"location":"reference/functions/#removebelowvalue","text":"removeBelowValue(N) Replaces series values with null if value N","title":"removeBelowValue"},{"location":"reference/functions/#transformnull","text":"transformNull(N) Replaces null values with N","title":"transformNull"},{"location":"reference/functions/#aggregate","text":"","title":"Aggregate"},{"location":"reference/functions/#aggregateby","text":"aggregateBy(interval, function) Takes all timeseries and consolidate all its points fallen in the given interval into one point using function , which can be one of: avg , min , max , median . Examples: aggregateBy(10m, avg) aggregateBy(1h, median)","title":"aggregateBy"},{"location":"reference/functions/#sumseries","text":"sumSeries() This will add metrics together and return the sum at each datapoint. This method required interpolation of each timeseries so it may cause high CPU load. Try to combine it with groupBy() function to reduce load.","title":"sumSeries"},{"location":"reference/functions/#percentileagg","text":"percentileAgg(interval, N) Takes all timeseries and consolidate all its points fallen in the given interval into one point by Nth percentile. Examples: percentileAgg(1h, 99) percentileAgg($__range_series, 95) - 95th percentile over all values","title":"percentileAgg"},{"location":"reference/functions/#average","text":"average(interval) Deprecated , use aggregateBy(interval, avg) instead.","title":"average"},{"location":"reference/functions/#min","text":"min(interval) Deprecated , use aggregateBy(interval, min) instead.","title":"min"},{"location":"reference/functions/#max","text":"max(interval) Deprecated , use aggregateBy(interval, max) instead.","title":"max"},{"location":"reference/functions/#filter","text":"","title":"Filter"},{"location":"reference/functions/#top","text":"top(N, value) Returns top N series, sorted by value , which can be one of: avg , min , max , median . Examples: top(10, avg) top(5, max)","title":"top"},{"location":"reference/functions/#bottom","text":"bottom(N, value) Returns bottom N series, sorted by value , which can be one of: avg , min , max , median . Examples: bottom(5, avg)","title":"bottom"},{"location":"reference/functions/#trends","text":"","title":"Trends"},{"location":"reference/functions/#trendvalue","text":"trendValue(valueType) Specifying type of trend value returned by Zabbix when trends are used (avg, min or max).","title":"trendValue"},{"location":"reference/functions/#time","text":"","title":"Time"},{"location":"reference/functions/#timeshift","text":"timeShift(interval) Draws the selected metrics shifted in time. If no sign is given, a minus sign ( - ) is implied which will shift the metric back in time. If a plus sign ( + ) is given, the metric will be shifted forward in time. Examples: timeShift(24h) - shift metric back in 24h hours timeShift(-24h) - the same result as for timeShift(24h) timeShift(+1d) - shift metric forward in 1 day","title":"timeShift"},{"location":"reference/functions/#alias","text":"Following template variables available for using in setAlias() and replaceAlias() functions: $__zbx_item , $__zbx_item_name - item name $__zbx_item_key - item key $__zbx_host_name - visible name of the host $__zbx_host - technical name of the host Examples: setAlias($__zbx_host_name: $__zbx_item) - backend01: CPU user time setAlias(Item key: $__zbx_item_key) - Item key: system.cpu.load[percpu,avg1] setAlias($__zbx_host_name) - backend01","title":"Alias"},{"location":"reference/functions/#setalias","text":"setAlias(alias) Returns given alias instead of the metric name. Examples: setAlias(load)","title":"setAlias"},{"location":"reference/functions/#setaliasbyregex","text":"setAliasByRegex(regex) Returns part of the metric name matched by regex. Examples: setAlias(Zabbix busy [a-zA-Z]+)","title":"setAliasByRegex"},{"location":"reference/functions/#replacealias","text":"replaceAlias(pattern, newAlias) Replace metric name using pattern. Pattern is regex or regular string. If regex is used, following special replacement patterns are supported: Pattern Inserts $$ Inserts a \"$\". $ Inserts the matched substring. $` Inserts the portion of the string that precedes the matched substring. $' Inserts the portion of the string that follows the matched substring. $n Where n is a non-negative integer less than 100, inserts the nth parenthesized submatch string, provided the first argument was a RegExp object. For more detais see String.prototype.replace() function. Examples: CPU system time replaceAlias(/CPU (.*) time/, $1) - system backend01: CPU system time replaceAlias(/CPU (.*) time/, $1) - backend01: system backend01: CPU system time replaceAlias(/.*CPU (.*) time/, $1) - system backend01: CPU system time replaceAlias(/(.*): CPU (.*) time/, $1 - $2) - backend01 - system","title":"replaceAlias"},{"location":"reference/functions/#special","text":"","title":"Special"},{"location":"reference/functions/#consolidateby","text":"consolidateBy(consolidationFunc) When a graph is drawn where width of the graph size in pixels is smaller than the number of datapoints to be graphed, plugin consolidates the values to to prevent line overlap. The consolidateBy() function changes the consolidation function from the default of average to one of sum , min , max or count . Valid function names are sum , avg , min , max and count .","title":"consolidateBy"},{"location":"reference/panel-triggers/","text":"","title":"Triggers Panel"},{"location":"tutorials/host_dashboard/","text":"","title":"Host dashboard"}]}